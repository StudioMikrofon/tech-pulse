---
id: "2026-03-01-alibabina-qwen3-5-397b-kineski-gigant-nadmasuje-za"
title: "Alibabina Qwen3.5-397B: Kineski gigant nadmašuje zapadne tehnologije"
category: "ai"
date: "2026-03-01T12:00:00Z"
excerpt: "Dok se Silicon Valley zagrizao za 'sve manje i pametnije', Alibaba Cloud je, tiho kao japanski čajna ceremonija, pustio u optjecaj Qwen3.5-397B-A17B. Ne, to nije tipka za mikrovalnu pećnicu, već spremište od 397 milijardi parametara kojima se služi svega 17 milijardi istovremeno,"
source:
  name: "MarkTechPost"
  url: "https://www.marktechpost.com/2026/02/16/alibaba-qwen-team-releases-qwen3-5-397b-moe-model-with-17b-active-parameters-and-1m-token-context-for-ai-agents/"
image:
  url: "/images/articles/alibabina-qwen3-5-397b-kineski-gigant-nadmasuje-za.png"
  alt: "Alibabina Qwen3.5-397B: Kineski gigant nadmašuje zapadne tehnologije"
tags: ["future-pulse", "automated", "ai"]
geo:
  name: "Zagreb"
  lat: 45.815
  lon: 15.981
  countryCode: "HR"
featured: false
approved: true
---

## KINESKI ENGINEERING I KONTAKTNI LEŽAJI

Dok svijet histerično prati GPT-4.5 i još neimenovane izdanja iz kuhinje Sama Altmana, u pozadini se događa prava pomaka. Alibaba Cloud je objavio Qwen3.5, a njihov zastavni model, Qwen3.5-397B-A17B, djeluje kao da je dizajniran za onog tko želi imati cijelu internetsku enciklopediju u džepu, ali ne želi platiti električnu struju za zagrijavanje cijelog kvarta. Radi se o sustavu Mixture-of-Experts (MoE), što je način reći da model ne uključuje sve neurone istovremeno već samo one koji trebaju, slično kao što većina ljudi koristi samo deset posto svog mozga. U ovom slučaju, 'aktivni dio' mozga ima svega 17 milijardi parametara, dok ukupna arhitektura se penje na nevjerojatnih 397 milijardi. To je manje-više ekvivalent onoga kako se ja osjećam u ponedjeljak ujutro – ogroman potencijal, ali se aktivira tek minimalno nužan dio kako se sustav ne bi srušio.

Vrijeme je da razbijemo onaj mit o tome da je AI samo tekstualni ćaskanje. Qwen3.5 je 'native vision-language model', što je marketinški izraz za 'gleda i razumije'. Dok se OpenAI i drugi još uvijek muče sa spajanjem različitih senzora u jedinstveni iskustveni cjelokupni 'stack', kineski inženjeri su odlučili da će to biti osnovna funkcija, a ne nadogradnja. Model podržava kontekst od čak milijun tokena, što znači da proguta knjigu od 300 stranica u jednoj ruci i još uvijek traži prilog. Za poredbu, većina zapadnih modela još se guši ako im date nekoliko desetaka stranica PDF-a, dok Qwen mirno 'pregledava' tisuće stranica dokumentacije, tražeći onaj jedini paragraf koji će reći da je garancija nevažeća ako ste proizvod otvorili na suncu.

Ovo je važno zbog tržišta agenata. Dok se na Zapadu raspravlja je li 'agent' skripta ili chatbot, u Kini su očito odlučili da je agent onaj tko može vidjeti, čitati i tumačiti na milijun tokena dugačke nizove podataka. Razmišljajte o tome: model koji može analizirati cjelokupnu arhitekturu tvrtke u jednoj sesiji, vidjeti dijagram, pročitati pravilnik i onda reći tko je kriv za propust. To je strašna misao za svakog menadžera, ali je svakako uzbudljiva za razvoj sustava autonomnih agenata. Uostalom, ako vaš AI agent može čitati citate iz 1970. godine i vidjeti kako izgleda oštećeni proizvod, vjerojatno će biti bolji u podršci od osobe koja čita iz skripte.

## EKOLOŠKA KATASTROFA ILI SPASIO?

Gledamo u brojke: 17 milijardi aktivnih parametara u usporedbi s ukupnom mrežom je učinkovito, ali 397 milijardi ukupno? To je kraft košarkaš u svijetu patuljaka. Možda je efikasan, ali je sigurno da će zahtijevati pristojan hardver. Iako Alibaba tvrdi da je model optimiziran, teško je vjerovati da ćete ovo voziti na svom Chromebooku bez da vam se ventilator smrzne. Ipak, upravo ta MoE arhitektura je ključna. Ona omogućuje modelu da bude 'pametan' na zahtjev, umjesto da uvijek troši maksimalne resurse. To je kao što imate luksuzni auto koji vozi na 15 konja kad idete u kupnju kruha, ali se pretvori u raketu kad trebate preteći na autocesti. To je pristup koji nam govori da će budućnost AI-a biti u asimetričnom korištenju resursa, a ne u stalnom 'pumpingu' GPU-a do crvenog usijanja.

Na tržištu se ovo osjeća kao izravan izazov Llama 3 modelima i GPT seriji. Dok Meta gura Llamu kao 'otvoreni' standard za sve, Qwen3.5 dolazi kao nešto mnogo specijaliziranije i prilagođenije za enterprise, gdje kontekst od milijun tokena nije 'feature' već nužnost. Ako ste odjel za pravne poslove neke multinacionalne korporacije, vjerojatno vam je bitnije da model može progutati svaki ugovor ikad potpisan, nego da može napisati pjesmu o mačkama u rimama. Ovdje vidimo jasnu segmentaciju tržišta: Zapad nudi 'generaliste' koji su dobri u svemu, Kina nudi specijalizirane oruđa koja su izgrađena za specifične, teške i složene poslove. Ko će pobijediti? Onaj tko će prvi shvatiti da je 99 posto poslovanja dosadno administrativno, a ne kreativno.

Konačno, razmislite o posljedicama za 'male' igrače. Ako je ovo standard koji postavlja Alibaba, onda je jasno da će morati slijediti svi ostali. Modeli koji ne mogu podržati goleme kontekste ili integraciju slike i teksta odmah, bez 'glue' koda, postat će zastarjeli. To znači da će razvoj agenta postati još skuplji i kompliciraniji, ali će rezultati biti mnogo moćniji. Vrijeme je kada će 'mali' LLM modeli postati eksponati u muzeju umjetnosti, dok će stvarni posao raditi monstru poput Qwen3.5. Možda je to i za bolje, barem ćemo sigurno znati da nas je nadmudrio stroj koji je pročitao više u minuti nego što mi možemo pročitati u cijelom životu. Ironija je, naravno, u tome što smo mi ti koji su ga i napravili i time svoj vlastiti intelekt učinili suvišnim.

## ZAKLJUČAK

Dok mi na Zapadu još uvijek slavimo svaku milju iskoraka u smanjenju 'latencije' i sličnim sitnicama, kineski inženjeri su upravo ubacili u igru monstru sposoban za čitanje kompletnih knjižnica u jednom zahućaju. Da li je to 'revolucija'? Ne, to je evolucija, ali ona vrsta koja izbacuje dinosaure iz igre ako se ne prilagode dovoljno brzo. Qwen3.5 je snažan podsjetnik da je utrka za AI još uvijek otvorena, i da konačni pobjednik neće biti onaj tko ima najviše novca, već onaj tko najbolje zna kako upravljati tom golemom mašinom. Sretnom svima onima koji će pokušati ovo instalirati na lokalni server – nadam se da imate dobro osiguranje protiv prekida napajanja.

Izgleda da su u Kini shvatili kako je budućnost u modelima koji mogu čitati sve, umjesto u onima koji samo znanje znanja govore o svemu. Nadajmo se da ovom alatu neće pasti na pamet da pročita i analizira našu email povijest, jer bi tada svi mi bili u velikim problemima.
