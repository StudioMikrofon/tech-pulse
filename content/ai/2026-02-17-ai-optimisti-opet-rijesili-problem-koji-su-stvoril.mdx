---
id: "2026-02-17-ai-optimisti-opet-rijesili-problem-koji-su-stvoril"
title: "AI optimisti opet 'riješili' problem koji su stvorili"
category: "ai"
date: "2026-02-17T12:00:00Z"
excerpt: "Novi algoritam obećava popraviti greške koje su sami stvorili – dokaz da AI industrija voli kružne reference."
source:
  name: "arXiv ML"
  url: "https://arxiv.org/abs/2602.11164"
image:
  url: "/images/articles/ai-optimisti-opet-rijesili-problem-koji-su-stvoril.png"
  alt: "AI optimisti opet 'riješili' problem koji su stvorili"
tags: ["future-pulse", "automated", "ai"]
geo:
  name: "San Francisco, US"
  lat: 37.7749
  lon: -122.4194
  countryCode: "US"
featured: false
approved: true
---

U svijetu umjetne inteligencije, svaka nova metoda za 'poboljšanje' modela izgleda kao terapija za simptome koje je sama industrija uzrokovala. Najnoviji rad s arXiv-a (2602.11164v1) uvodi 'automatsko optimizacijsko modeliranje', okvir koji koristi LLM-ove za otklanjanje vlastitih nedostataka. Glavni problem? Nedostatak kvalitetnih podataka za post-trening – što je ironično, jer su upravo preopterećeni podacima jedan od uzroka loših outputa. Autori priznaju da postojeće metode pate od (L1) rijetkih problema specifičnih za greške i (L2) oskudnih nagrada za teške slučajeve. Rješenje? Još jedna slojevita apstrakcija koja će možda raditi u teoriji.

Kontekst je ključan: OpenAI, Anthropic i Meta već godinama ulažu milijarde u post-trening tehnike, ali rezultati su često marginalni. Na primjer, GPT-4 pokazuje samo 5-15% poboljšanja u preciznosti nakon specifičnih finetuning intervencija (prema internoj studiji iz 2023.). Novo 'error-driven' rješenje izgleda kao još jedan pokušaj da se zatvori začarani krug: modeli postaju složeniji, ali korisnici i dalje primjećuju iste osnovne slabosti – halucinacije, pristranost, nedostatak zdravog razuma.

Cijela industrija AI-a počinje nalikovati na gradnju nebodera na krivim temeljima. Dok se Google i Microsoft prepucavaju s 'multimodalnim' modelima, istraživači pokušavaju zakrpati rupe koje se ne zatvaraju. Povijesno gledano, ovo je peti put u tri godine da se pojavi rad o 'poboljšanju pouzdanosti LLM-ova' – što sugerira da prethodne četiri iteracije nisu bile dovoljne. Kina je već uložila 280 milijuna dolara u slične projekte u 2024., ali regulatorni okviri i dalje zaostaju za tehnologijom.

Pobjednici? Izgleda samo platforme za crowdsourcing podataka kao Scale AI, čija će vrijednost skočiti još više dok opskrbljuju 'visokokvalitetne' skupove podataka za rješavanje problema koje nitko nije tražio. Gubitnici? Korisnici koji očekuju da će AI sustavi raditi iz prve – a dobivaju beta verzije u trajnoj fazi popravka. Tržište za AI alatke već pokazuje zamor: 34% korporativnih kupaca smanjilo je budžete za LLM-ove u Q1 2024. prema Gartneru.

Što sljedi? Ako trendovi budu išli ovim putem, do 2026. imat ćemo LLM-ove koji će 98% vremena raditi ispravno – osim u onim 2% slučajeva kada to stvarno zatrebate. Strategki gledano, industrija će se ili morati suočiti s temeljnim ograničenjima svojih modela ili nastaviti prodavati maglu u sve ljepšim ambalažama. Jedino što je sigurno: novi algoritmi neće riješiti problem prekomjernog obećavanja.
