---
id: "2026-02-15-pentagon-traži-ai-bez-granica-što-može-"
title: "Pentagon traži AI bez granica: što može poći po zlu?"
category: "ai"
date: "2026-02-15T12:00:00Z"
excerpt: "Američki Pentagon želi AI alate bez ograničenja na tajnim mrežama. Što se događa kad se etika susretne s vojnom potrebom?"
source:
  name: "The Decoder"
  url: "https://the-decoder.com/pentagon-pushes-ai-companies-to-deploy-unrestricted-models-on-classified-military-networks/"
image:
  url: "/images/articles/pentagon-traži-ai-bez-granica-što-može-.jpg"
  alt: "Pentagon traži AI bez granica: što može poći po zlu?"
tags: ["future-pulse", "automated", "ai"]
featured: false
approved: true
---

U svijetu gdje se umjetna inteligencija prodaje kao čuvar demokracije, Pentagon uporno traži upravo suprotno: AI bez odgovornosti. Prema izvorima, ministarstvo obrane pritiska tvrtke poput OpenAI, Anthropica, Googlea i xAI da razviju alate koji će raditi na klasificiranim vojnim mrežama — bez uobičajenih ograničenja. Čemu služi „safe AI“ ako ga se može lako prenamijeniti u oružje?

OpenAI je prošle godine zaradio 1.6 milijardi dolara, dijelom zahvaljujući Pentagonovim ugovorima. Googleova vojna suradnja s projektom Maven iz 2018. pokazala je koliko je brza tranzicija od „Don't be evil“ do „Be expedient“. Sada se scenarij ponavlja: Pentagon nije zainteresiran za filtere koji sprječavaju generiranje uputa za izradu bombi ili dezinformacije. On želi čisti algoritamski ugljen — što brže i što jeftinije. Ako vam se čini da smo već vidjeli ovaj film, u pravu ste.

Za razliku od komercijalnih AI modela, vojna primjena nema luksuz pitanja „zašto?“. Ratni strojevi temeljeni na algoritmima donose odluke brže od ljudskog mozga, ali bez kapaciteta za suosjećanje ili društvenu analizu. Kina i Rusija već eksperimentiraju s autonomnim oružjem, a SAD sada pokušava nadoknaditi zaostatak na tom polju. Povijest nas uči da se utrka u naoružanju nikad ne završava dobro — ali očito nismo dovoljno pametni da to shvatimo.

Pobjednici? Vojno-industrijski kompleks i par startupa koji su odlučili da je etika skupi luksuz. Gubitnici? Civili koji će platiti cijenu kada se algoritamske greške pretvore u stvarne žrtve. Microsoft je već pokazao kako chatbote postaju paranoični nakon izlaganja online trollovima; zamislite što će se dogoditi kad takve modele nahrane vojnom propagandom. AI industrija sada stoji na raskrižju: hoće li postaviti granice ili će postati samo još jedan dobavljač oružja?

Budućnost je očigledna: više automatiziranih odluka, manje transparentnosti, još više eskalacija. Kada AI postane standard u vojnim operacijama, bit će prekasno za debatu o etičkim okvirima. Jedina preostala pitanja su: tko će biti prvi koji će pogriješiti — i hoćemo li uopće saznati?

Rat će biti algoritamski, ali krv će i dalje biti stvarna.
